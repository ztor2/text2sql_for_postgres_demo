{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ztor2/text2sql_for_postgres_demo/blob/main/text2sql_for_postgres_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChCbVA-xV8i8",
        "outputId": "a956078f-f3d1-4ea6-b97c-d74d957346b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw2U8LucXrSk",
        "outputId": "e5968644-0afc-4da5-ded6-a867af3d4261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/sqlgen_agens\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/sqlgen_agens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3c1Vhuvztwz3"
      },
      "outputs": [],
      "source": [
        "# !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n",
        "# !sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "# !wget https://developer.download.nvidia.com/compute/cuda/12.3.1/local_installers/cuda-repo-ubuntu2204-12-3-local_12.3.1-545.23.08-1_amd64.deb\n",
        "!sudo dpkg -i cuda-repo-ubuntu2204-12-3-local_12.3.1-545.23.08-1_amd64.deb\n",
        "!sudo cp /var/cuda-repo-ubuntu2204-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
        "!sudo apt-get update\n",
        "!sudo apt-get -y install cuda-toolkit-12-3;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pr4VlS9dXW8o"
      },
      "outputs": [],
      "source": [
        "!pip install ctransformers\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nGn2JqbeS6B1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# from transformers import AutoModelForCausalLM\n",
        "from ctransformers import AutoModelForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import psycopg2\n",
        "import psycopg2.extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP_M305XTHOk"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"TheBloke/neural-chat-7B-v3-3-GGUF\", model_file=\"neural-chat-7b-v3-3.Q5_K_M.gguf\", model_type=\"mistral\", gpu_layers=100, hf=True)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"TheBloke/zephyr-7B-beta-GGUF\", model_file=\"zephyr-7b-beta.Q8_0.gguf\", model_type=\"mistral\", gpu_layers=50, hf=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Intel/neural-chat-7b-v3-3\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC6jSBCzTHT9"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYvPTbieBYN8"
      },
      "outputs": [],
      "source": [
        "system = \"Generate a PostgreSQL query or provide proper information to answer the following question based on database schema: \"\n",
        "warn = \" If the user's question is not related to SQL generation, tell them to submit a SQL-related question. \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZovtN6RO9PM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYhhm2FXBU46"
      },
      "outputs": [],
      "source": [
        "def format_message(message: str, history: list, memory_limit: int=3) -> str:\n",
        "\n",
        "    if len(history) > memory_limit:\n",
        "        history = history[-memory_limit:]\n",
        "\n",
        "    global completed_prompt\n",
        "    completed_prompt = \"### System: \" + f\"{system}\" + f\"{dbinfo}\" + f\" {warn}\"\n",
        "    for i, [user_msg, model_answer] in enumerate(history):\n",
        "       completed_prompt += f\"### User: {user_msg} ### Assistant: {model_answer}\"\n",
        "    completed_prompt += \" ### User: \" + f\"{message}\"\n",
        "\n",
        "    return completed_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2-QgDh1THAv"
      },
      "outputs": [],
      "source": [
        "def get_response(message: str, history: list) -> str:\n",
        "\n",
        "    query = format_message(message, history)\n",
        "    response = \"\"\n",
        "    sequences = pipe(\n",
        "        query,\n",
        "        max_new_tokens=400,\n",
        "        do_sample=True,\n",
        "        temperature=0.5,\n",
        "        top_k=25,\n",
        "        top_p=0.95,\n",
        "        use_cache=False)\n",
        "\n",
        "    generated_text = sequences[0]['generated_text']\n",
        "    response = generated_text[len(query):]\n",
        "    print(\"Chatbot:\", response.strip())\n",
        "\n",
        "    return response.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEFpLcT0TVdY"
      },
      "outputs": [],
      "source": [
        "def tab1_click(a, b, c, d, e, f, g, h):\n",
        "\n",
        "    try:\n",
        "        conn = psycopg2.connect(\n",
        "        host=a,\n",
        "        port=b,\n",
        "        user=c,\n",
        "        password=d,\n",
        "        database=e\n",
        "        )\n",
        "        cursor = conn.cursor(cursor_factory = psycopg2.extras.RealDictCursor)\n",
        "        if f == '' and g == '':\n",
        "            cursor.execute(f\"\"\"SELECT table_schema_name AS schema_name, table_name, column_name\n",
        "                               FROM information_schema.columns;\n",
        "                               \"\"\")\n",
        "\n",
        "        elif f != '' and g == '':\n",
        "            cursor.execute(f\"\"\"SELECT table_schema AS schema_name, table_name, column_namee\n",
        "                               FROM information_schema.columns\n",
        "                               WHERE table_schema = '{f}';\n",
        "                               \"\"\")\n",
        "\n",
        "        elif f == '' and g != '':\n",
        "            cursor.execute(f\"\"\"SELECT table_schema AS schema_name, table_name, column_name\n",
        "                               FROM information_schema.columns\n",
        "                               WHERE table_name ='{g}';\n",
        "                               \"\"\")\n",
        "\n",
        "        elif f != '' and g != '':\n",
        "            cursor.execute(f\"\"\"SELECT table_schema AS schema_name, table_name, column_name\n",
        "                               FROM information_schema.columns\n",
        "                               WHERE table_schema = '{f}'\n",
        "                               AND table_name ='{g}';\n",
        "                               \"\"\")\n",
        "\n",
        "        global dbinfo\n",
        "        dbinfo = cursor.fetchall()\n",
        "        dbinfo = [dict(row) for row in dbinfo]\n",
        "        dbinfo = str(dbinfo)\n",
        "        dbinfo += f\" additional schema description: {h}\"\n",
        "    except:\n",
        "        return \"Error occurred\"\n",
        "\n",
        "    return \"Successfully connected to \" + a + \" / \"+ b + \" / \"+ c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8233gRnTXgo"
      },
      "outputs": [],
      "source": [
        "def tab2_click(a):\n",
        "\n",
        "    try:\n",
        "        global dbinfo\n",
        "        dbinfo = f\"{a}\"\n",
        "    except:\n",
        "        return \"Error occurred\"\n",
        "\n",
        "    return \"Successfully updated database information.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qZmSMjuoAnO"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "with gr.Blocks(theme=gr.themes.Monochrome()) as demo:\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"# üêò SQL Generator for AgensSQL&PostgreSQL\")\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"\"\"- Convert natural language queries into SQL queries that match your DB.\n",
        "                    \\n - Connect to a DB by entering the DB info of AgensSQL or PostgreSQL family in '**Connect to DB**'.\n",
        "                    \\n - For DBs that don't support connections, you can enter info directly under \"**Enter DB info manually**\".\n",
        "                    \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            with gr.Tab(\"Connect to DB\"):\n",
        "                host = gr.Textbox(value=\"175.125.**.***\", label=\"Host\", lines=1)\n",
        "                port = gr.Textbox(value=\"5432\", label=\"Port\", lines=1)\n",
        "                user = gr.Textbox(value=\"postgres\", label=\"User\", lines=1)\n",
        "                pwd = gr.Textbox(value=\"password\", label=\"Password\", lines=1, type=\"password\")\n",
        "                db = gr.Textbox(value=\"agchat\", label=\"Database\", lines=1)\n",
        "                scm = gr.Textbox(value=\"agchat\", label=\"Schema(optional)\", lines=1)\n",
        "                tbl = gr.Textbox(value=\"tb_chat\", label=\"Table(optional)\", lines=1)\n",
        "                add = gr.Textbox(value=\"This is the log table of AgensDesk app.\", label=\"Description(optional)\", lines=1)\n",
        "                info = gr.Textbox(value=\"\", label=\"Status\", lines=2)\n",
        "                btn = gr.Button(value=\"Connect\")\n",
        "                btn.click(tab1_click, inputs=[host, port, user, pwd, db, scm, tbl, add], outputs=[info])\n",
        "            with gr.Tab(\"Enter DB info manually\"):\n",
        "                input_dbinfo = gr.Textbox(value=\"I have table named 'test', it has 3 columns, 'student', 'subect', 'score'\", label=\"Description\", lines=16)\n",
        "                info = gr.Textbox(value=\"\", label=\"Status\", lines=2)\n",
        "                btn2 = gr.Button(value=\"Enter\")\n",
        "                btn2.click(tab2_click, inputs=[input_dbinfo], outputs=[info])\n",
        "        with gr.Column(scale=3):\n",
        "            chat = gr.ChatInterface(get_response,\n",
        "                                    retry_btn='Retry',\n",
        "                                    undo_btn='Undo',\n",
        "                                    clear_btn='Clear ',\n",
        "                                    submit_btn='Submit ')\n",
        "demo.launch(share=True)\n",
        "# demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-WYeassud8h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOiBjmNnlQ9sAJzTrdqaJ4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}